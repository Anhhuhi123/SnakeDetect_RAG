# ğŸ BÃ¡o CÃ¡o Hiá»‡u Suáº¥t Models PhÃ¢n Loáº¡i Ráº¯n

## ğŸ“Š Tá»•ng Quan Dataset
- **Sá»‘ lÆ°á»£ng classes**: 124 loÃ i ráº¯n Viá»‡t Nam
- **Dataset structure**: Train / Validation / Test split
- **Image size**: 224Ã—224 pixels
- **Augmentation**: AutoAugment, RandAugment, CutMix, MixUp

---

## ğŸ† Báº£ng So SÃ¡nh Hiá»‡u Suáº¥t Models

| Model | Test Accuracy | PhÆ°Æ¡ng PhÃ¡p |
|-------|---------------|-------------|
| **Swin-S + CutMix + MixUp & Swin Tiny** | **97.46%** | Ensemble Model |
| **Swin-S + CutMix + MixUp** | **94.01%** | CutMix + MixUp + AutoAugment + Label Smoothing |
| **Swin-S + CutMix** | **93.72%** ğŸ¥‡ | CutMix + AutoAugment + Label Smoothing |
| **Swin-S (Baseline)** | **93.00%** ğŸ¥ˆ | Basic Augmentation + Label Smoothing |
| **Swin Tiny** | **92.57%** ğŸ¥‰ | Basic Augmentation |
| **ConvNeXt Tiny** | **92.13%** | AutoAugment + Label Smoothing |
| **EfficientNetV2** |  **91.33%** | RandAugment |
---

## ğŸ“ˆ Chi Tiáº¿t Tá»«ng Model

### 1ï¸âƒ£ **Swin-S + CutMix + MixUp & Swin Tiny (Ensemble)** ğŸ† (Test: 97.46%)

**PhÆ°Æ¡ng phÃ¡p:**
- **Ensemble Model**: Káº¿t há»£p dá»± Ä‘oÃ¡n tá»« 2 models (Swin-S + CutMix + MixUp vÃ  Swin Tiny)
- **Voting/Averaging**: Láº¥y trung bÃ¬nh hoáº·c vote tá»« cáº£ 2 models
- **Complementary Strengths**: Models khÃ¡c nhau bá»• trá»£ cho nhau

**Ãch lá»£i:**
- âœ… Accuracy cao nháº¥t (97.46%) - TÄƒng ~3.5% so vá»›i single model
- âœ… Robust hÆ¡n, giáº£m sai sá»‘ nhá» káº¿t há»£p nhiá»u quan Ä‘iá»ƒm
- âœ… Cáº£i thiá»‡n Ä‘áº·c biá»‡t tá»‘t trÃªn cÃ¡c classes khÃ³

---

### 2ï¸âƒ£ **Swin-S + CutMix + MixUp** ğŸ¥‡ (Test: 94.01%)

**PhÆ°Æ¡ng phÃ¡p:**
- **CutMix**: Cáº¯t vÃ  ghÃ©p cÃ¡c pháº§n cá»§a 2 áº£nh khÃ¡c nhau
- **MixUp**: Trá»™n 2 áº£nh theo tá»‰ lá»‡
- **AutoAugment**: Tá»± Ä‘á»™ng tÃ¬m augmentation tá»‘t nháº¥t
- **Label Smoothing**: LÃ m má»m labels

**Ãch lá»£i:**
- âœ… Accuracy ráº¥t cao (94.01%)
- âœ… Regularization máº¡nh nháº¥t (CutMix + MixUp)
- âœ… TrÃ¡nh overfitting xuáº¥t sáº¯c
- âœ… Generalization tá»‘t nháº¥t trong single models

---

### 3ï¸âƒ£ **Swin-S + CutMix** ğŸ¥ˆ (Test: 93.72%)

**PhÆ°Æ¡ng phÃ¡p:**
- **CutMix**: Cáº¯t vÃ  ghÃ©p cÃ¡c pháº§n cá»§a 2 áº£nh khÃ¡c nhau â†’ Model há»c Ä‘Æ°á»£c Ä‘áº·c Ä‘iá»ƒm tá»« nhiá»u vá»‹ trÃ­
- **AutoAugment**: Tá»± Ä‘á»™ng tÃ¬m augmentation tá»‘t nháº¥t
- **Label Smoothing**: LÃ m má»m labels Ä‘á»ƒ trÃ¡nh model quÃ¡ tá»± tin â†’ Giáº£m overfitting

**Ãch lá»£i:**
- âœ… Accuracy cao (93.72%)
- âœ… TrÃ¡nh overfitting tá»‘t nhá» CutMix
- âœ… Nháº­n diá»‡n ráº¯n tá»‘t ngay cáº£ khi bá»‹ che khuáº¥t má»™t pháº§n
- âœ… ÄÆ¡n giáº£n hÆ¡n version cÃ³ MixUp

---

### 4ï¸âƒ£ **Swin-S (Baseline)** ï¿½ (Test: 93.00%)

**PhÆ°Æ¡ng phÃ¡p:**
- **Swin Transformer**: Kiáº¿n trÃºc hiá»‡n Ä‘áº¡i dÃ¹ng window attention
- **Label Smoothing**: LÃ m má»m labels
- **Basic Augmentation**: Chá»‰ dÃ¹ng flip, resize cÆ¡ báº£n

**Ãch lá»£i:**
- âœ… Training Ä‘Æ¡n giáº£n, nhanh hÆ¡n
- âœ… á»”n Ä‘á»‹nh, dá»… reproduce
- âœ… Baseline tá»‘t Ä‘á»ƒ so sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c

---

### 5ï¸âƒ£ **Swin Tiny** (Test: 92.57%)

**PhÆ°Æ¡ng phÃ¡p:**
- **Swin Transformer phiÃªn báº£n nhá»**: Giáº£m sá»‘ layers vÃ  params
- **Basic Augmentation**: Augmentation cÆ¡ báº£n

**Ãch lá»£i:**
- âœ… Nhanh hÆ¡n Swin-S (~50% faster)
- âœ… Model nhá» hÆ¡n, dá»… deploy
- âœ… Accuracy váº«n tá»‘t (92.57%)
- âœ… PhÃ¹ há»£p khi cáº§n balance giá»¯a tá»‘c Ä‘á»™ vÃ  chÃ­nh xÃ¡c

---

### 6ï¸âƒ£ **ConvNeXt Tiny** (Test: 92.13%)

**PhÆ°Æ¡ng phÃ¡p:**
- **ConvNeXt**: CNN hiá»‡n Ä‘áº¡i vá»›i thiáº¿t káº¿ giá»‘ng Transformer
- **AutoAugment**: Tá»± Ä‘á»™ng tÃ¬m augmentation
- **Label Smoothing**: Giáº£m overfitting

**Ãch lá»£i:**
- âœ… Inference nhanh nháº¥t (khÃ´ng cáº§n attention mechanism phá»©c táº¡p)
- âœ… Dá»… deploy hÆ¡n Swin
- âœ… PhÃ¹ há»£p khi cáº§n tá»‘c Ä‘á»™

---

### 7ï¸âƒ£ **EfficientNetV2** (Test: 91.33%)

**PhÆ°Æ¡ng phÃ¡p:**
- **EfficientNetV2**: Kiáº¿n trÃºc Ä‘Æ°á»£c tá»‘i Æ°u cho tá»‘c Ä‘á»™ vÃ  hiá»‡u quáº£
- **RandAugment**: Random augmentation
- **Progressive Learning**: Há»c tá»« áº£nh nhá» Ä‘áº¿n lá»›n

**Ãch lá»£i:**
- âœ… Model nhá» gá»n nháº¥t
- âœ… Training nhanh
- âœ… PhÃ¹ há»£p cho mobile/edge devices

### 5ï¸âƒ£ **EfficientNetV2**
**File**: `NB_EfficientNetV2.ipynb`

**Hiá»‡u suáº¥t:**
- âœ… **Best Validation Accuracy**: ~87-89% (Æ°á»›c tÃ­nh)
- âš¡ **Training Speed**: Nhanh nháº¥t (~2h)

**Cáº¥u hÃ¬nh:**
```python
Model: EfficientNetV2-S
Optimizer: AdamW
Loss: CrossEntropyLoss
Augmentation: RandAugment
```

**Æ¯u Ä‘iá»ƒm:**
- âš¡ **Training + Inference nhanh nháº¥t**
- ğŸ’¾ **Model size nhá» nháº¥t** (~21M params)
- ğŸ”‹ GPU memory efficient
- ğŸ“± PhÃ¹ há»£p mobile/edge deployment

**NhÆ°á»£c Ä‘iá»ƒm:**
- ğŸ“‰ Accuracy tháº¥p nháº¥t (~87-89%)
- ğŸ¯ KÃ©m hÆ¡n ~5-7% so vá»›i Swin-S

**Cáº£i tiáº¿n Ä‘á» xuáº¥t:**
1. **EfficientNetV2-M/L**: TÄƒng model capacity
2. **Progressive learning**: Start vá»›i small images, tÄƒng dáº§n
3. **CutMix**: EfficientNet benefit nhiá»u tá»« CutMix
4. **Longer training**: Train 40-50 epochs vá»›i cosine decay

---

### 6ï¸âƒ£ **Swin Tiny**
**File**: `NB_SwinTiny.ipynb`

**Hiá»‡u suáº¥t:**
- âœ… **Best Validation Accuracy**: ~88-90% (Æ°á»›c tÃ­nh)
- ğŸ“Š Model size: ~28M params

**Æ¯u Ä‘iá»ƒm:**
- âš¡ Nhanh hÆ¡n Swin-S
- ğŸ’¾ Model size nhá» hÆ¡n
- ğŸ¯ Balance tá»‘t giá»¯a speed vÃ  accuracy

**NhÆ°á»£c Ä‘iá»ƒm:**
- ğŸ“‰ Accuracy tháº¥p hÆ¡n Swin-S ~4-5%

**Cáº£i tiáº¿n Ä‘á» xuáº¥t:**
1. **CutMix + MixUp**: CÃ³ thá»ƒ Ä‘áº¡t 91-92%
2. **Knowledge Distillation**: Learn tá»« Swin-S teacher
3. **Longer training**: 40-50 epochs

---

## ğŸ¯ Khuyáº¿n Nghá»‹ Chá»n Model

### ğŸ† **Production Use (Priority: Accuracy)**
```
â†’ Swin-S + CutMix (94.32%)
   - Best accuracy
   - á»”n Ä‘á»‹nh nháº¥t
   - Worth the computational cost
```

---

## ğŸ¯ Khuyáº¿n Nghá»‹ Chá»n Model

**ğŸ† Æ¯u tiÃªn Accuracy cao nháº¥t:**
```
â†’ Swin-S + CutMix (93.72%)
```

**âš¡ Æ¯u tiÃªn Tá»‘c Ä‘á»™ vÃ  Deploy dá»…:**
```
â†’ ConvNeXt Tiny (92.13%)
```

**âš–ï¸ CÃ¢n báº±ng giá»¯a Accuracy vÃ  ÄÆ¡n giáº£n:**
```
â†’ Swin-S Baseline (93.00%)
```

---

## ğŸš€ HÆ°á»›ng Cáº£i Tiáº¿n

**1. TÄƒng accuracy thÃªm 0.5-1%:**
- Ensemble nhiá»u models
- Test Time Augmentation (TTA)
- Train thÃªm epochs vá»›i learning rate tháº¥p hÆ¡n

**2. Tá»‘i Æ°u cho deployment:**
- Knowledge Distillation: Chuyá»ƒn kiáº¿n thá»©c tá»« Swin-S â†’ model nhá» hÆ¡n
- Model quantization: Giáº£m tá»« FP32 â†’ INT8
- ONNX export Ä‘á»ƒ deploy Ä‘a ná»n táº£ng

**3. Cáº£i thiá»‡n classes khÃ³:**
- Thu tháº­p thÃªm data cho classes cÃ³ accuracy tháº¥p
- Focal Loss Ä‘á»ƒ táº­p trung vÃ o samples khÃ³
- Data augmentation máº¡nh hÆ¡n cho classes thiá»ƒu sá»‘
---

## ğŸ“š Giáº£i ThÃ­ch Thuáº­t Ngá»¯

**CutMix**: Cáº¯t 1 pháº§n áº£nh A vÃ  dÃ¡n vÃ o áº£nh B â†’ Model há»c Ä‘Æ°á»£c Ä‘áº·c Ä‘iá»ƒm á»Ÿ nhiá»u vá»‹ trÃ­ khÃ¡c nhau

**MixUp**: Trá»™n 2 áº£nh vá»›i nhau theo tá»‰ lá»‡ â†’ Model khÃ´ng quÃ¡ tá»± tin vÃ o 1 class duy nháº¥t

**Label Smoothing**: Thay vÃ¬ label cá»©ng (0 hoáº·c 1), dÃ¹ng label má»m (0.05 vÃ  0.95) â†’ TrÃ¡nh overfitting

**AutoAugment**: Tá»± Ä‘á»™ng tÃ¬m cÃ¡ch augment áº£nh tá»‘t nháº¥t (xoay, láº­t, thay Ä‘á»•i mÃ u sáº¯c...)

**Swin Transformer**: Kiáº¿n trÃºc AI hiá»‡n Ä‘áº¡i, xá»­ lÃ½ áº£nh theo tá»«ng "cá»­a sá»•" nhá» â†’ Hiá»‡u quáº£ hÆ¡n

**ConvNeXt**: CNN cáº£i tiáº¿n, káº¿t há»£p Æ°u Ä‘iá»ƒm cá»§a CNN vÃ  Transformer â†’ Nhanh mÃ  váº«n chÃ­nh xÃ¡c

---

**Last Updated**: 28/10/2025  
**Best Model**: Swin-S + CutMix (93.72% Test Acc)

